*Инструкция по запуску:*
1. Создать файлы с переменными окружения по примерам с названиями '.env.example': 
    - 'postgresql/.env'
    - 'kafka/.env'
    - 'api/src/core/.env'
2. Нужен установленный Docker Compose.
3. Выполнить команду в терминале:
```bash
docker compose -f docker-compose.dev.yml up --build
```



**Задание:** разработка API для обработки и публикации данных.

**Цель:** проверить навыки проектирования API, работы с PostgreSQL, интеграции Kafka и практического применения FastAPI.

**Сценарий:** вы работаете над системой обработки данных для аналитической платформы. Данные поступают в систему через API, сохраняются в PostgreSQL, а затем публикуются в Kafka для последующей обработки другими сервисами.

**Вам нужно:** создать REST API, которое: 
  - принимает JSON данные от пользователя;
  - сохраняет данные в таблице PostgreSQL; 
  - валидирует входящие данные;
  - публикует эти данные в Kafka;
  - реализовывает endpoint для получения списка всех сохраненных записей.

**Требования.**
1. База данных (PostgreSQL).
  Создать таблицу data_entries со следующими полями:
    - id (serial primary key);
    - content (jsonb) — данные в формате JSON;
    - created_at (timestamp) — время создания записи.
2. API (FastAPI).
  Endpoint 1: POST /data
    - принимает JSON в теле запроса;
    - валидирует наличие поля content (строка, обязательное);
    - сохраняет данные в таблицу data_entries;
    - публикует данные в Kafka с ключом data_entry;
    - возвращает ID сохраненной записи.
  Endpoint 2: GET /data
    - возвращает все записи из таблицы data_entries.
3. Kafka.
  Создать продюсер, который публикует каждую запись в тему data_topic.

**Критерии оценки.**
1. Архитектура и стиль кода.
    - использование Pydantic для валидации данных;
    - применение асинхронного подхода (async/await).
2. Работа с базой данных.
    - использование SQLAlchemy или другой ORM;
    - корректная работа с транзакциями.
3. Интеграция с Kafka.
    - использование библиотеки для работы с Kafka (например, aiokafka); 
    - правильное конфигурирование Kafka-продюсера.
4. Логирование и обработка ошибок.
    - добавление логов с использованием loguru;
    - корректная обработка ошибок (например, неправильные входные данные).

**Документация.**
  - автоматическая генерация документации с FastAPI;
  - понятные комментарии в коде.

**Пример данных.**
  - запрос к POST /data;
  ```json
  {
      "content": "Hello, Kafka!"
  }
  ```
  - ответ от POST /data;
  ```json
  {
      "id": 1,
      "message": "Data saved and published to Kafka."
  }
  ```

  - ответ от GET /data.
  ```json
  [
      {
          "id": 1,
          "content": "Hello, Kafka!",
          "created_at": "2024-12-03T10:00:00"
      }
  ]
  ```
